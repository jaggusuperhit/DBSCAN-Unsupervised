{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hi! Choosing a movie is a real struggle for many of us :) So most of the streaming platforms have inbuild recommendation systems. These systems aim to predict user's interests and recommend items that they'll probably like. Throughout this notebook, we will try to use 2 clasterisation methods to build our own movie recommender.\n",
    "\n",
    "#### We are going to use three following data sets:\n",
    "[Netflix TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/netflix-tv-shows-and-movies?datasetId=2178661&sortBy=voteCount)  \n",
    "[HBO Max TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/hbo-max-tv-shows-and-movies?select=titles.csv)  \n",
    "[Amazon Prime TV Shows and Movies](https://www.kaggle.com/datasets/victorsoeiro/amazon-prime-tv-shows-and-movies?select=titles.csv)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Libraries\n",
    "First, let's import the necessary libraries for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:29:59.681032Z",
     "iopub.status.busy": "2022-12-07T16:29:59.680552Z",
     "iopub.status.idle": "2022-12-07T16:30:00.585777Z",
     "shell.execute_reply": "2022-12-07T16:30:00.584661Z",
     "shell.execute_reply.started": "2022-12-07T16:29:59.680943Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# sklearn\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data imports (3 datasets already mentioned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:30:00.588220Z",
     "iopub.status.busy": "2022-12-07T16:30:00.587883Z",
     "iopub.status.idle": "2022-12-07T16:30:00.870705Z",
     "shell.execute_reply": "2022-12-07T16:30:00.869841Z",
     "shell.execute_reply.started": "2022-12-07T16:30:00.588190Z"
    }
   },
   "outputs": [],
   "source": [
    "df_netflix = pd.read_csv('credits.csv')\n",
    "df_amazon =  pd.read_csv('title.csv')\n",
    "df_hbo =  pd.read_csv('titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:30:00.872552Z",
     "iopub.status.busy": "2022-12-07T16:30:00.871771Z",
     "iopub.status.idle": "2022-12-07T16:30:00.891413Z",
     "shell.execute_reply": "2022-12-07T16:30:00.890500Z",
     "shell.execute_reply.started": "2022-12-07T16:30:00.872520Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df_netflix, df_amazon, df_hbo], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>role</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>age_certification</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3748.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>Travis Bickle</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14658.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Jodie Foster</td>\n",
       "      <td>Iris Steensma</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7064.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Albert Brooks</td>\n",
       "      <td>Tom</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3739.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Harvey Keitel</td>\n",
       "      <td>Matthew 'Sport' Higgins</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48933.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Cybill Shepherd</td>\n",
       "      <td>Betsy</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id       id             name                character   role title  \\\n",
       "0     3748.0  tm84618   Robert De Niro            Travis Bickle  ACTOR   NaN   \n",
       "1    14658.0  tm84618     Jodie Foster            Iris Steensma  ACTOR   NaN   \n",
       "2     7064.0  tm84618    Albert Brooks                      Tom  ACTOR   NaN   \n",
       "3     3739.0  tm84618    Harvey Keitel  Matthew 'Sport' Higgins  ACTOR   NaN   \n",
       "4    48933.0  tm84618  Cybill Shepherd                    Betsy  ACTOR   NaN   \n",
       "\n",
       "  type description  release_year age_certification  runtime genres  \\\n",
       "0  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "1  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "2  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "3  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "4  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "\n",
       "  production_countries  seasons imdb_id  imdb_score  imdb_votes  \\\n",
       "0                  NaN      NaN     NaN         NaN         NaN   \n",
       "1                  NaN      NaN     NaN         NaN         NaN   \n",
       "2                  NaN      NaN     NaN         NaN         NaN   \n",
       "3                  NaN      NaN     NaN         NaN         NaN   \n",
       "4                  NaN      NaN     NaN         NaN         NaN   \n",
       "\n",
       "   tmdb_popularity  tmdb_score  \n",
       "0              NaN         NaN  \n",
       "1              NaN         NaN  \n",
       "2              NaN         NaN  \n",
       "3              NaN         NaN  \n",
       "4              NaN         NaN  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df_movies.drop(['description', 'age_certification'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>role</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>age_certification</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "      <th>tmdb_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3748.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Robert De Niro</td>\n",
       "      <td>Travis Bickle</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14658.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Jodie Foster</td>\n",
       "      <td>Iris Steensma</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7064.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Albert Brooks</td>\n",
       "      <td>Tom</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3739.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Harvey Keitel</td>\n",
       "      <td>Matthew 'Sport' Higgins</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48933.0</td>\n",
       "      <td>tm84618</td>\n",
       "      <td>Cybill Shepherd</td>\n",
       "      <td>Betsy</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_id       id             name                character   role title  \\\n",
       "0     3748.0  tm84618   Robert De Niro            Travis Bickle  ACTOR   NaN   \n",
       "1    14658.0  tm84618     Jodie Foster            Iris Steensma  ACTOR   NaN   \n",
       "2     7064.0  tm84618    Albert Brooks                      Tom  ACTOR   NaN   \n",
       "3     3739.0  tm84618    Harvey Keitel  Matthew 'Sport' Higgins  ACTOR   NaN   \n",
       "4    48933.0  tm84618  Cybill Shepherd                    Betsy  ACTOR   NaN   \n",
       "\n",
       "  type description  release_year age_certification  runtime genres  \\\n",
       "0  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "1  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "2  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "3  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "4  NaN         NaN           NaN               NaN      NaN    NaN   \n",
       "\n",
       "  production_countries  seasons imdb_id  imdb_score  imdb_votes  \\\n",
       "0                  NaN      NaN     NaN         NaN         NaN   \n",
       "1                  NaN      NaN     NaN         NaN         NaN   \n",
       "2                  NaN      NaN     NaN         NaN         NaN   \n",
       "3                  NaN      NaN     NaN         NaN         NaN   \n",
       "4                  NaN      NaN     NaN         NaN         NaN   \n",
       "\n",
       "   tmdb_popularity  tmdb_score  \n",
       "0              NaN         NaN  \n",
       "1              NaN         NaN  \n",
       "2              NaN         NaN  \n",
       "3              NaN         NaN  \n",
       "4              NaN         NaN  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### working with production_countries column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          NaN\n",
       "1          NaN\n",
       "2          NaN\n",
       "3          NaN\n",
       "4          NaN\n",
       "         ...  \n",
       "3289    ['PR']\n",
       "3290    ['PA']\n",
       "3291        []\n",
       "3292        []\n",
       "3293    ['US']\n",
       "Name: production_countries, Length: 90966, dtype: object"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['production_countries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. Remove unwanted characters from the 'production_countries' column\n",
    "# The .str.replace() method is used to remove '[' and ']' characters, and any single quotes\n",
    "# The 'regex=True' flag allows the .str.replace() method to interpret the patterns as regular expressions.\n",
    "# Note: Square brackets [ ] are special characters in regex, so they are not part of character set and needs escaping.\n",
    "df_movies['production_countries'] = df_movies['production_countries'].str.replace(r\"\\[\", '', regex=True).str.replace(r\"'\", '', regex=True).str.replace(r\"\\]\", '', regex=True)\n",
    "\n",
    "# 2. Extract the first country from the cleaned 'production_countries' column\n",
    "# The .str.split(',') splits the string into a list using commas as the delimiter, then .str[0] selects the first element.\n",
    "# This creates a new column 'lead_prod_country' that represents the primary production country of each movie\n",
    "df_movies['lead_prod_country'] = df_movies['production_countries'].str.split(',').str[0]\n",
    "\n",
    "# 3. Calculate the number of countries involved in the production of each movie\n",
    "# The .str.split(',') splits the 'production_countries' string by commas, and .str.len() counts the number of elements in the resulting list.\n",
    "# This new column 'prod_countries_cnt' stores the count of production countries for each movie, providing additional data insights\n",
    "df_movies['prod_countries_cnt'] = df_movies['production_countries'].str.split(',').str.len()\n",
    "\n",
    "# 4. Replace any empty values in the 'lead_prod_country' column with NaN (Not a Number)\n",
    "# This step uses the .replace() method to convert any empty strings ('') to np.nan (missing values)\n",
    "# Handling missing data with NaN is important for accurate data analysis and prevents errors in downstream processing\n",
    "df_movies['lead_prod_country'] = df_movies['lead_prod_country'].replace('', np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       NaN\n",
       "1       NaN\n",
       "2       NaN\n",
       "3       NaN\n",
       "4       NaN\n",
       "       ... \n",
       "3289     PR\n",
       "3290     PA\n",
       "3291    NaN\n",
       "3292    NaN\n",
       "3293     US\n",
       "Name: lead_prod_country, Length: 90933, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['lead_prod_country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Working with genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        NaN\n",
       "1                        NaN\n",
       "2                        NaN\n",
       "3                        NaN\n",
       "4                        NaN\n",
       "                ...         \n",
       "3289    ['romance', 'music']\n",
       "3290              ['comedy']\n",
       "3291              ['comedy']\n",
       "3292              ['comedy']\n",
       "3293       ['documentation']\n",
       "Name: genres, Length: 90933, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['genres']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Remove unwanted characters from the 'genres' column\n",
    "# The .str.replace() method is used to remove '[' and ']' characters, and any single quotes from the 'genres' column\n",
    "# This cleans the 'genres' data by removing extraneous characters, making it easier to analyze and manipulate\n",
    "# Note: Square brackets [ ] are special characters in regex, so they need escaping with a backslash (\\).\n",
    "df_movies['genres'] = df_movies['genres'].str.replace(r\"\\[\", '', regex=True).str.replace(r\"'\", '', regex=True).str.replace(r\"\\]\", '', regex=True)\n",
    "\n",
    "# 2. Extract the first genre from the cleaned 'genres' column\n",
    "# The .str.split(',') splits the 'genres' string by commas, and .str[0] selects the first element of the resulting list\n",
    "# This creates a new column 'main_genre' that represents the primary genre of each movie\n",
    "df_movies['main_genre'] = df_movies['genres'].str.split(',').str[0]\n",
    "\n",
    "# . Replace any empty values in the 'main_genre' column with NaN (Not a Number)\n",
    "# This step uses the .replace() method to convert any empty strings ('') to np.nan, indicating missing data\n",
    "# Handling missing data with NaN is important for accurate data analysis and prevents errors in downstream processing\n",
    "df_movies['main_genre'] = df_movies['main_genre'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 NaN\n",
       "1                 NaN\n",
       "2                 NaN\n",
       "3                 NaN\n",
       "4                 NaN\n",
       "            ...      \n",
       "3289          romance\n",
       "3290           comedy\n",
       "3291           comedy\n",
       "3292           comedy\n",
       "3293    documentation\n",
       "Name: main_genre, Length: 90933, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies['main_genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Drop unnecessary columns 'genres' and 'production_countries' from the DataFrame\n",
    "# The .drop() method with 'axis=1' removes specified columns, as they are no longer needed after extracting the main genre and production country count\n",
    "df_movies.drop(['genres', 'production_countries'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90933, 18)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person_id             13132\n",
       "id                        0\n",
       "name                  13132\n",
       "character             22904\n",
       "role                  13132\n",
       "title                 77801\n",
       "type                  77801\n",
       "release_year          77801\n",
       "runtime               77801\n",
       "seasons               88831\n",
       "imdb_id               78794\n",
       "imdb_score            79194\n",
       "imdb_votes            79215\n",
       "tmdb_popularity       78380\n",
       "tmdb_score            80146\n",
       "lead_prod_country     78732\n",
       "prod_countries_cnt    77801\n",
       "main_genre            78063\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any missing values to clean the dataset\n",
    "df_movies.dropna(inplace=True)\n",
    "\n",
    "# Set the 'title' column as the DataFrame index\n",
    "df_movies.set_index('title', inplace=True)\n",
    "\n",
    "# Drop the 'id' and 'imdb_id' columns as they are not needed for further analysis\n",
    "df_movies.drop(['id', 'imdb_id'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 15)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Categorical Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for categorical columns ('type', 'lead_prod_country', 'main_genre')\n",
    "dummies = pd.get_dummies(df_movies[['type', 'lead_prod_country', 'main_genre']], drop_first=True)\n",
    "\n",
    "# Concatenate the dummy variables with the original DataFrame\n",
    "df_movies_dum = pd.concat([df_movies, dummies], axis=1)\n",
    "\n",
    "# 14. Drop the original categorical columns after creating dummy variables\n",
    "df_movies_dum.drop(['type', 'lead_prod_country', 'main_genre'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling (MinmaxScaler):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame is empty. Cannot apply MinMaxScaler.\n"
     ]
    }
   ],
   "source": [
    "if not df_movies_dum.empty:\n",
    "    scaler = MinMaxScaler()\n",
    "    df_scaled = scaler.fit_transform(df_movies_dum)\n",
    "    df_scaled = pd.DataFrame(df_scaled, columns=df_movies_dum.columns)\n",
    "else:\n",
    "    print(\"DataFrame is empty. Cannot apply MinMaxScaler.\")\n",
    "    # You can either return, skip scaling, or handle it based on your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Apply MinMaxScaler to scale the data for model training\n",
    "# scaler = MinMaxScaler()\n",
    "# df_scaled = scaler.fit_transform(df_movies_dum)\n",
    "# df_scaled = pd.DataFrame(df_scaled, columns=df_movies_dum.columns)\n",
    "\n",
    "# # Display the scaled DataFrame\n",
    "\n",
    "# df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "# step 4: DBSCAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### run a loop to get best epsilon value and minpnts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:36:39.457619Z",
     "iopub.status.busy": "2022-12-07T16:36:39.456879Z",
     "iopub.status.idle": "2022-12-07T16:37:07.484641Z",
     "shell.execute_reply": "2022-12-07T16:37:07.483657Z",
     "shell.execute_reply.started": "2022-12-07T16:36:39.457550Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m eps_array:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m min_samples \u001b[38;5;129;01min\u001b[39;00m min_samples_array:\n\u001b[32m      8\u001b[39m         \u001b[38;5;66;03m# Initialize and fit the DBSCAN model with the current parameters\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m         clusterer = DBSCAN(eps=eps, min_samples=min_samples).fit(\u001b[43mdf_scaled\u001b[49m)\n\u001b[32m     11\u001b[39m         \u001b[38;5;66;03m# Retrieve the cluster labels from the fitted model\u001b[39;00m\n\u001b[32m     12\u001b[39m         cluster_labels = clusterer.labels_\n",
      "\u001b[31mNameError\u001b[39m: name 'df_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "# Define the range of epsilon (eps) and minimum samples (min_samples) parameters for DBSCAN\n",
    "eps_array = [0.2, 0.5, 1]  # List of different epsilon values (the maximum distance between two samples for one to be considered as in the neighborhood of the other)\n",
    "min_samples_array = [5, 10, 30]  # List of different min_samples values (the number of samples in a neighborhood for a point to be considered as a core point)\n",
    "\n",
    "# Iterate over each combination of eps and min_samples\n",
    "for eps in eps_array:\n",
    "    for min_samples in min_samples_array:\n",
    "        # Initialize and fit the DBSCAN model with the current parameters\n",
    "        clusterer = DBSCAN(eps=eps, min_samples=min_samples).fit(df_scaled)\n",
    "        \n",
    "        # Retrieve the cluster labels from the fitted model\n",
    "        cluster_labels = clusterer.labels_\n",
    "        \n",
    "        # Check if the algorithm found only one cluster or marked all points as noise (-1 label for noise)\n",
    "        if len(set(cluster_labels)) == 1:\n",
    "            continue  # Skip this combination as it does not provide meaningful clusters\n",
    "        \n",
    "        # Calculate the silhouette score to evaluate the quality of the clustering\n",
    "        silhouette_avg = silhouette_score(df_scaled, cluster_labels)\n",
    "        \n",
    "        # Print the current parameters, number of clusters, and the silhouette score\n",
    "        print(\"For eps =\", eps,\n",
    "              \"For min_samples =\", min_samples,\n",
    "              \"Count clusters =\", len(set(cluster_labels)),\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN With Best Hypterparameters (eps=1, minpnts=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:07.486451Z",
     "iopub.status.busy": "2022-12-07T16:37:07.485997Z",
     "iopub.status.idle": "2022-12-07T16:37:10.741424Z",
     "shell.execute_reply": "2022-12-07T16:37:10.740145Z",
     "shell.execute_reply.started": "2022-12-07T16:37:07.486410Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[67]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m dbscan_model = DBSCAN(eps=\u001b[32m1\u001b[39m, min_samples=\u001b[32m5\u001b[39m).fit(\u001b[43mdf_scaled\u001b[49m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFor eps =\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m,\n\u001b[32m      3\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mFor min_samples =\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m5\u001b[39m,\n\u001b[32m      4\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mCount clusters =\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mset\u001b[39m(dbscan_model.labels_)),\n\u001b[32m      5\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mThe average silhouette_score is :\u001b[39m\u001b[33m\"\u001b[39m, silhouette_score(df_scaled, dbscan_model.labels_))\n",
      "\u001b[31mNameError\u001b[39m: name 'df_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "dbscan_model = DBSCAN(eps=1, min_samples=5).fit(df_scaled)\n",
    "print(\"For eps =\", 1,\n",
    "      \"For min_samples =\", 5,\n",
    "      \"Count clusters =\", len(set(dbscan_model.labels_)),\n",
    "      \"The average silhouette_score is :\", silhouette_score(df_scaled, dbscan_model.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### save clusters for recommendations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.743395Z",
     "iopub.status.busy": "2022-12-07T16:37:10.742933Z",
     "iopub.status.idle": "2022-12-07T16:37:10.750695Z",
     "shell.execute_reply": "2022-12-07T16:37:10.749339Z",
     "shell.execute_reply.started": "2022-12-07T16:37:10.743352Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dbscan_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_movies[\u001b[33m'\u001b[39m\u001b[33mdbscan_clusters\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdbscan_model\u001b[49m.labels_\n",
      "\u001b[31mNameError\u001b[39m: name 'dbscan_model' is not defined"
     ]
    }
   ],
   "source": [
    "df_movies['dbscan_clusters'] = dbscan_model.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'dbscan_clusters'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLP\\DBSCAN-Unsupervised\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'dbscan_clusters'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf_movies\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdbscan_clusters\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.value_counts()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLP\\DBSCAN-Unsupervised\\myenv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLP\\DBSCAN-Unsupervised\\myenv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'dbscan_clusters'"
     ]
    }
   ],
   "source": [
    "df_movies['dbscan_clusters'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"6\"></a> <br>\n",
    "# Step 5: Movie Recommendation Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our data is ready to use the clustering results to try and recommend a movie by the name of the one you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.752815Z",
     "iopub.status.busy": "2022-12-07T16:37:10.752432Z",
     "iopub.status.idle": "2022-12-07T16:37:10.761746Z",
     "shell.execute_reply": "2022-12-07T16:37:10.760529Z",
     "shell.execute_reply.started": "2022-12-07T16:37:10.752784Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend_movie(movie_name: str):\n",
    "    # Convert the input movie name to lowercase for case-insensitive matching\n",
    "    movie_name = movie_name.lower()\n",
    "\n",
    "    # Create a new column 'name' with lowercase movie names for comparison\n",
    "    df_movies['name'] = df_movies.index.str.lower()\n",
    "\n",
    "    # Find the movie that matches the input name\n",
    "    movie = df_movies[df_movies['name'].str.contains(movie_name, na=False)]\n",
    "\n",
    "    if not movie.empty:\n",
    "        # Get the cluster label of the input movie\n",
    "        cluster = movie['dbscan_clusters'].values[0]\n",
    "\n",
    "        # Get all movies in the same cluster\n",
    "        cluster_movies = df_movies[df_movies['dbscan_clusters'] == cluster]\n",
    "\n",
    "        # If there are more than 5 movies in the cluster, randomly select 5\n",
    "        if len(cluster_movies) >= 5:\n",
    "            recommended_movies = random.sample(list(cluster_movies.index), 5)\n",
    "        else:\n",
    "            # If fewer than 5, return all the movies in the cluster\n",
    "            recommended_movies = list(cluster_movies.index)\n",
    "\n",
    "        # Print the recommended movies\n",
    "        print('--- We can recommend you these movies ---')\n",
    "        for m in recommended_movies:\n",
    "            print(m)\n",
    "    else:\n",
    "        print('Movie not found in the database.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ‰ Now we can input a random movie name and get 5 movies that our model recommends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.763655Z",
     "iopub.status.busy": "2022-12-07T16:37:10.763337Z",
     "iopub.status.idle": "2022-12-07T16:38:23.429558Z",
     "shell.execute_reply": "2022-12-07T16:38:23.428365Z",
     "shell.execute_reply.started": "2022-12-07T16:37:10.763626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Movie not found in the database.\n"
     ]
    }
   ],
   "source": [
    "s = input('Input movie name: ')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "recommend_movie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Movie not found in the database.\n"
     ]
    }
   ],
   "source": [
    "s = input('Input movie name: ')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "recommend_movie(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Movie not found in the database.\n"
     ]
    }
   ],
   "source": [
    "s = input('Input movie name: ')\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "recommend_movie(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streamlit App (so save df_movies dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_movies.to_csv(\"clustered_movies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
